{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import forward\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as Data\n",
    "import data_loader as dl\n",
    "import train as tt\n",
    "import sys\n",
    "import os\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copydir(n):\n",
    "    os.system(f\"cp data0 data{n} -r\")\n",
    "    os.system(f\"cp generate_data0 generate_data{n} -r\")\n",
    "    item=os.listdir(f\"data{n}\")\n",
    "    os.mkdir(f\"data{n}/train\")\n",
    "    os.mkdir(f\"data{n}/test\")\n",
    "    for i in item:\n",
    "        if \".npy\" in i:\n",
    "            data = np.load(f\"data{n}/{i}\")\n",
    "            state = np.random.uniform(0,1,size=(len(data)))\n",
    "            train = data[state >= 0.2]\n",
    "            test = data [state < 0.2]\n",
    "            np.save(f\"data{n}/train/{i}\",train)\n",
    "            np.save(f\"data{n}/test/{i}\",test)\n",
    "    \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=tt.sgrna_net().cuda()\n",
    "#net=torch.load(\"generate_data/model/500.pt\")\n",
    "lossf=nn.SmoothL1Loss(reduction=\"mean\")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datat in range(1,20):\n",
    "    copydir(datat)\n",
    "    torch.manual_seed(1024)\n",
    "    net=tt.sgrna_net().cuda()\n",
    "    train=dl.data_loader(dic=f\"./data{datat}/train\")\n",
    "    #train,va = Data.random_split(data,[int(len(data)*0.8),len(data)-int(len(data)*0.8)])\n",
    "    test=dl.data_loader(dic=f\"./data{datat}/test\")\n",
    "    trloader=Data.DataLoader(dataset=train,batch_size=5000,shuffle=True)\n",
    "    #valoader=Data.DataLoader(dataset=va ,batch_size=5000,shuffle=True)\n",
    "    testloader = Data.DataLoader(dataset=test,batch_size=1000,shuffle=True)\n",
    "    opt=torch.optim.Adam(filter(lambda p : p.requires_grad, net.parameters()),lr=0.001)\n",
    "    she=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt,T_0=5)   \n",
    "    steps=40000\n",
    "    wt1=open(f\"./generate_data{datat}/traj/trloss\",\"w+\")\n",
    "    wt2=open(f\"./generate_data{datat}/traj/valoss\",\"w+\")\n",
    "    #net=torch.load(\"generate_data/model/500.pt\")\n",
    "    lossf=nn.SmoothL1Loss(reduction=\"mean\")\n",
    "    print(net)\n",
    "    for _ in range(steps):\n",
    "        net.train()\n",
    "        for seq,typ,eff in trloader:\n",
    "            seq=seq.cuda()\n",
    "            typ=typ.cuda()\n",
    "            eff=eff.cuda()\n",
    "            eff+=(torch.rand(size=eff.size(),device=\"cuda\")-0.5)*0.1\n",
    "            eff =torch.abs(eff)\n",
    "            pre=net(seq,typ)\n",
    "            loss=lossf(pre,eff)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            she.step()\n",
    "        print(loss.detach().cpu().numpy(),file=wt1,flush=True)\n",
    "\n",
    "        net.eval()\n",
    "        for seq,typ,eff in testloader:\n",
    "            seq=seq.cuda()\n",
    "            typ=typ.cuda()\n",
    "            eff=eff.cuda()\n",
    "            pre=net(seq,typ)\n",
    "            loss=lossf(pre,eff)\n",
    "        print(loss.detach().cpu().numpy(),file=wt2,flush=True)\n",
    "\n",
    "        if _%100 ==0:\n",
    "            presave=[]\n",
    "            effsave=[]\n",
    "            for seq,typ,eff in trloader:\n",
    "                seq=seq.cuda()\n",
    "                typ=typ.cuda()\n",
    "                eff=eff.cuda()\n",
    "                pre=net(seq,typ)\n",
    "                pre=pre.detach().cpu().numpy()\n",
    "                eff=eff.detach().cpu().numpy()\n",
    "                if len(presave)==0:\n",
    "                    presave=np.copy(pre)\n",
    "                    effsave=np.copy(eff)\n",
    "                else:\n",
    "                    presave=np.concatenate((presave,pre))\n",
    "                    effsave=np.concatenate((effsave,eff))\n",
    "                \n",
    "            np.save(f\"./generate_data{datat}/out/effv\"+\"_\"+str(_),effsave)\n",
    "            np.save(f\"./generate_data{datat}/out/prev\"+\"_\"+str(_),presave)\n",
    "\n",
    "            presave=[]\n",
    "            effsave=[]\n",
    "            for seq,typ,eff in testloader:\n",
    "                seq=seq.cuda()\n",
    "                typ=typ.cuda()\n",
    "                eff=eff.cuda()\n",
    "                pre=net(seq,typ)\n",
    "                pre=pre.detach().cpu().numpy()\n",
    "                eff=eff.detach().cpu().numpy()\n",
    "                if len(presave)==0:\n",
    "                    presave=np.copy(pre)\n",
    "                    effsave=np.copy(eff)\n",
    "                else:\n",
    "                    presave=np.concatenate((presave,pre))\n",
    "                    effsave=np.concatenate((effsave,eff))\n",
    "                \n",
    "            np.save(f\"./generate_data{datat}/out/eff\"+\"_\"+str(_),effsave)\n",
    "            np.save(f\"./generate_data{datat}/out/pre\"+\"_\"+str(_),presave)\n",
    "\n",
    "            torch.save(net,f\"./generate_data{datat}/model/\"+str(_)+\".pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
